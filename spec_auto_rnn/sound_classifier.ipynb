{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = 499\n",
    "hidden_layer = 5\n",
    "\n",
    "sampling_rate = 200\n",
    "striding = 100\n",
    "train_steps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onset-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seizure_time_parser(onset_times,patient_number,data_set_number):\n",
    "    temp = str(onset_times[patient_number-1][data_set_number])\n",
    "    curr_onset_time = []\n",
    "    while temp.find('/')!=-1:\n",
    "        curr_onset_time.append(int(temp[0:temp.find('/')]))\n",
    "        temp=temp[temp.find('/')+1:]\n",
    "    curr_onset_time.append(int(float(temp)))\n",
    "    curr_onset_time=np.array(curr_onset_time)\n",
    "    return curr_onset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seizure_file = open('/home/maestroj/medical_analysis/project2/seizure_times.csv','r',newline='')\n",
    "reader = csv.reader(seizure_file,delimiter=',')\n",
    "onset_times_temp=[]\n",
    "\n",
    "for row in reader:\n",
    "    onset_times_temp.append(row)\n",
    "    \n",
    "onset_times = []\n",
    "total_patient = len(onset_times_temp)\n",
    "event_number = np.zeros(total_patient,dtype=np.int32)\n",
    "#number of events of (i+1) patient = event_number[i]\n",
    "\n",
    "for i in range(total_patient):\n",
    "    event_number[i] = len(onset_times_temp[i])-1\n",
    "\n",
    "for p in range(total_patient):\n",
    "    temp = []\n",
    "    for d in range(event_number[p]):\n",
    "        temp.append(seizure_time_parser(onset_times_temp,p+1,d+1))\n",
    "    onset_times.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The number of datasets of patients\")\n",
    "print(event_number)\n",
    "print(\"1st patient's seizure time for each data_set\")\n",
    "print(onset_times[0][1])\n",
    "print(\"9th patient's seizure time for each data_set\")\n",
    "print(onset_times[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stft_load(patient_number, dataset_number):\n",
    "    input_folder_path = '/home/maestroj/medical_analysis/stft_data/'\n",
    "    input_data_name = '{}_{}.csv'.format(patient_number,dataset_number)\n",
    "    input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "    input_file = open(input_data_path,'r',newline='')\n",
    "    reader = csv.reader(input_file, delimiter=',')\n",
    "    print(\"{} is loaded\".format(input_data_name))\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    try:\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    except: \n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[0])):\n",
    "                temp[i][j]=abs(complex(temp[i][j].replace('i','j')))\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "        temp = np.transpose(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stft_normal(dataset_number):\n",
    "    input_folder_path = '/home/maestroj/medical_analysis/stft_normal/'\n",
    "    input_data_name = '{}.csv'.format(dataset_number)\n",
    "    input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "    input_file = open(input_data_path,'r',newline='')\n",
    "    reader = csv.reader(input_file, delimiter=',')\n",
    "    print(\"{} is loaded\".format(input_data_name))\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    try:\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    except: \n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[0])):\n",
    "                temp[i][j]=abs(complex(temp[i][j].replace('i','j')))\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "        temp = np.transpose(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_axis_maker(array, sec_per_cell,init = 0):\n",
    "    final = init + sec_per_cell*(len(array)-1)\n",
    "    return np.linspace(init,final,len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "restorer = tf.train.import_meta_graph('auto.meta')\n",
    "sess = tf.Session()\n",
    "restorer.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "inputs = tf.get_collection(\"input\")\n",
    "X = inputs[0]\n",
    "outputs = tf.get_collection(\"hypo\")\n",
    "H = outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train_set and test_set generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_data = []\n",
    "train_output_data = []\n",
    "test_input_data = []\n",
    "test_output_data = []\n",
    "one_hot = np.eye(4)\n",
    "for i in range(4):\n",
    "    train_index = 0.7*nsounds[i]\n",
    "    for j in range(1,nsounds[i]+1):\n",
    "        try :\n",
    "            result = music_loader(i,j)\n",
    "            y = result['y']\n",
    "            D = librosa.stft(y,win_length=win_length, hop_length= hop_length)\n",
    "            D = np.transpose(abs(D))\n",
    "            if D.shape[0] < train_length:\n",
    "                continue\n",
    "                \n",
    "            if j < train_index:\n",
    "                train_input_data.append(sess.run(H, feed_dict={X : D[0:train_length]}))\n",
    "                train_output_data.append(one_hot[i])\n",
    "            else :\n",
    "                test_input_data.append(sess.run(H, feed_dict={X : D[0:train_length]}))\n",
    "                test_output_data.append(one_hot[i])\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found\")\n",
    "test_input_data = np.array(test_input_data)\n",
    "test_output_data = np.array(test_output_data)\n",
    "train_input_data = np.array(train_input_data)\n",
    "train_output_data = np.array(train_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 40, 10)\n",
      "(144, 4)\n",
      "(62, 40, 10)\n",
      "(62, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train and test set\")\n",
    "print(train_input_data.shape)\n",
    "print(train_output_data.shape)\n",
    "print(test_input_data.shape)\n",
    "print(test_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
