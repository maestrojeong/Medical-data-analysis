{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = 499\n",
    "hidden_layer = 5\n",
    "\n",
    "sampling_rate = 200\n",
    "striding = 100\n",
    "train_steps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Onset-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seizure_time_parser(onset_times,patient_number,data_set_number):\n",
    "    temp = str(onset_times[patient_number-1][data_set_number])\n",
    "    curr_onset_time = []\n",
    "    while temp.find('/')!=-1:\n",
    "        curr_onset_time.append(int(temp[0:temp.find('/')]))\n",
    "        temp=temp[temp.find('/')+1:]\n",
    "    curr_onset_time.append(int(float(temp)))\n",
    "    curr_onset_time=np.array(curr_onset_time)\n",
    "    return curr_onset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seizure_file = open('/home/maestroj/medical_analysis/project2/seizure_times.csv','r',newline='')\n",
    "reader = csv.reader(seizure_file,delimiter=',')\n",
    "onset_times_temp=[]\n",
    "\n",
    "for row in reader:\n",
    "    onset_times_temp.append(row)\n",
    "    \n",
    "onset_times = []\n",
    "total_patient = len(onset_times_temp)\n",
    "event_number = np.zeros(total_patient,dtype=np.int32)\n",
    "#number of events of (i+1) patient = event_number[i]\n",
    "\n",
    "for i in range(total_patient):\n",
    "    event_number[i] = len(onset_times_temp[i])-1\n",
    "\n",
    "for p in range(total_patient):\n",
    "    temp = []\n",
    "    for d in range(event_number[p]):\n",
    "        temp.append(seizure_time_parser(onset_times_temp,p+1,d+1))\n",
    "    onset_times.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of datasets of patients\n",
      "[ 7  7  6  3 10  1  7 13 16  8  8  5  3  6 31  8  2  4]\n",
      "1st patient's seizure time for each data_set\n",
      "[781]\n",
      "9th patient's seizure time for each data_set\n",
      "[array([200]), array([312]), array([624]), array([762]), array([752]), array([772]), array([884]), array([502]), array([ 94, 258]), array([836]), array([650]), array([636]), array([576]), array([656]), array([638]), array([706])]\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of datasets of patients\")\n",
    "print(event_number)\n",
    "print(\"1st patient's seizure time for each data_set\")\n",
    "print(onset_times[0][1])\n",
    "print(\"9th patient's seizure time for each data_set\")\n",
    "print(onset_times[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def stft_load(patient_number, dataset_number):\n",
    "    input_folder_path = '/home/maestroj/medical_analysis/stft_data/'\n",
    "    input_data_name = '{}_{}.csv'.format(patient_number,dataset_number)\n",
    "    input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "    input_file = open(input_data_path,'r',newline='')\n",
    "    reader = csv.reader(input_file, delimiter=',')\n",
    "    print(\"{} is loaded\".format(input_data_name))\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    try:\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    except: \n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[0])):\n",
    "                temp[i][j]=abs(complex(temp[i][j].replace('i','j')))\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "        temp = np.transpose(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stft_normal(dataset_number):\n",
    "    input_folder_path = '/home/maestroj/medical_analysis/stft_normal/'\n",
    "    input_data_name = '{}.csv'.format(dataset_number)\n",
    "    input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "    input_file = open(input_data_path,'r',newline='')\n",
    "    reader = csv.reader(input_file, delimiter=',')\n",
    "    print(\"{} is loaded\".format(input_data_name))\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    try:\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    except: \n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[0])):\n",
    "                temp[i][j]=abs(complex(temp[i][j].replace('i','j')))\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    temp = np.transpose(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def time_axis_maker(array, sec_per_cell,init = 0):\n",
    "    final = init + sec_per_cell*(len(array)-1)\n",
    "    return np.linspace(init,final,len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_1.csv is loaded\n",
      "(499, 32769)\n"
     ]
    }
   ],
   "source": [
    "temp = stft_load(8,1)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1.csv is loaded\n",
      "1_2.csv is loaded\n",
      "1_3.csv is loaded\n",
      "1_4.csv is loaded\n",
      "1_5.csv is loaded\n",
      "1_6.csv is loaded\n",
      "1_7.csv is loaded\n",
      "2_1.csv is loaded\n",
      "2_2.csv is loaded\n",
      "2_3.csv is loaded\n",
      "2_4.csv is loaded\n",
      "2_5.csv is loaded\n",
      "2_6.csv is loaded\n",
      "2_7.csv is loaded\n",
      "3_1.csv is loaded\n",
      "3_5.csv is loaded\n",
      "3_6.csv is loaded\n",
      "4_1.csv is loaded\n",
      "4_2.csv is loaded\n",
      "4_3.csv is loaded\n",
      "5_2.csv is loaded\n",
      "5_3.csv is loaded\n",
      "5_4.csv is loaded\n",
      "6_1.csv is loaded\n",
      "7_1.csv is loaded\n",
      "7_2.csv is loaded\n",
      "7_3.csv is loaded\n",
      "7_4.csv is loaded\n",
      "7_5.csv is loaded\n",
      "7_6.csv is loaded\n",
      "7_7.csv is loaded\n",
      "8_1.csv is loaded\n",
      "8_2.csv is loaded\n",
      "8_3.csv is loaded\n",
      "8_4.csv is loaded\n",
      "8_5.csv is loaded\n",
      "8_6.csv is loaded\n",
      "8_7.csv is loaded\n",
      "8_9.csv is loaded\n",
      "8_10.csv is loaded\n",
      "8_11.csv is loaded\n",
      "8_12.csv is loaded\n",
      "8_13.csv is loaded\n",
      "9_3.csv is loaded\n",
      "9_4.csv is loaded\n",
      "9_5.csv is loaded\n",
      "9_6.csv is loaded\n",
      "9_7.csv is loaded\n",
      "9_8.csv is loaded\n",
      "9_10.csv is loaded\n",
      "9_11.csv is loaded\n",
      "9_12.csv is loaded\n",
      "9_13.csv is loaded\n",
      "9_14.csv is loaded\n",
      "9_15.csv is loaded\n",
      "9_16.csv is loaded\n",
      "11_1.csv is loaded\n",
      "11_2.csv is loaded\n",
      "11_3.csv is loaded\n",
      "11_4.csv is loaded\n",
      "11_5.csv is loaded\n",
      "11_6.csv is loaded\n",
      "11_7.csv is loaded\n",
      "11_8.csv is loaded\n",
      "12_1.csv is loaded\n",
      "13_1.csv is loaded\n",
      "13_2.csv is loaded\n",
      "13_3.csv is loaded\n",
      "14_1.csv is loaded\n",
      "14_2.csv is loaded\n",
      "14_3.csv is loaded\n",
      "14_4.csv is loaded\n",
      "14_5.csv is loaded\n",
      "14_6.csv is loaded\n",
      "15_1.csv is loaded\n",
      "15_2.csv is loaded\n",
      "15_3.csv is loaded\n",
      "15_9.csv is loaded\n",
      "15_10.csv is loaded\n",
      "15_13.csv is loaded\n",
      "15_14.csv is loaded\n",
      "15_15.csv is loaded\n",
      "15_16.csv is loaded\n",
      "15_18.csv is loaded\n",
      "15_19.csv is loaded\n",
      "15_21.csv is loaded\n",
      "15_22.csv is loaded\n",
      "15_23.csv is loaded\n",
      "15_24.csv is loaded\n",
      "15_25.csv is loaded\n",
      "15_26.csv is loaded\n",
      "15_27.csv is loaded\n",
      "15_29.csv is loaded\n",
      "15_30.csv is loaded\n",
      "16_1.csv is loaded\n",
      "16_2.csv is loaded\n",
      "16_3.csv is loaded\n",
      "16_4.csv is loaded\n",
      "16_5.csv is loaded\n",
      "16_6.csv is loaded\n",
      "16_7.csv is loaded\n",
      "16_8.csv is loaded\n",
      "17_1.csv is loaded\n",
      "17_2.csv is loaded\n",
      "18_1.csv is loaded\n",
      "18_3.csv is loaded\n",
      "18_4.csv is loaded\n",
      "(1957323,)\n"
     ]
    }
   ],
   "source": [
    "input_data = []\n",
    "for i in range(total_patient):\n",
    "    for j in range(event_number[i]):\n",
    "        try:\n",
    "            temp = stft_load(i+1,j+1)\n",
    "            for k in range(len(temp)):\n",
    "                input_data.append(temp[k])\n",
    "        except FileNotFoundError:\n",
    "            continue;\n",
    "input_data = np.array(input_data)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/add:0\", shape=(1000, 1), dtype=float32)\n",
      "Tensor(\"rnn/add_1:0\", shape=(1500, 1), dtype=float32)\n",
      "Tensor(\"rnn/Reshape_2:0\", shape=(1000, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32,[None,input_size])\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([input_size,hidden_layer], -0.01, 0.01))\n",
    "b1 = tf.Variable(tf.random_uniform([1, hidden_layer], -0.01, 0.01))\n",
    "\n",
    "w2 = tf.Variable(tf.random_uniform([hidden_layer,input_size], -0.01, 0.01))\n",
    "b2 = tf.Variable(tf.random_uniform([1, input_size], -0.01, 0.01))\n",
    "\n",
    "H = tf.matmul(X, w1) + b1\n",
    "hypothesis = tf.matmul(H, w2) + b2\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(X-hypothesis))\n",
    "optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(train_steps+1):\n",
    "    sess.run(train, feed_dict={X: input_data})\n",
    "    if step%100==0:\n",
    "        print(\"{}th run cost : {} \".format(step, sess.run(cost, feed_dict={X : input_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.add_to_collection(\"input\", X)\n",
    "tf.add_to_collection(\"hypo\", H)\n",
    "saver.save(sess, 'auto')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
