{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = 32769\n",
    "hidden_layer = 5\n",
    "\n",
    "normal = 18\n",
    "\n",
    "sampling_rate = 200\n",
    "striding = 100\n",
    "train_steps = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Onset-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seizure_time_parser(onset_times,patient_number,data_set_number):\n",
    "    temp = str(onset_times[patient_number-1][data_set_number])\n",
    "    curr_onset_time = []\n",
    "    while temp.find('/')!=-1:\n",
    "        curr_onset_time.append(int(temp[0:temp.find('/')]))\n",
    "        temp=temp[temp.find('/')+1:]\n",
    "    curr_onset_time.append(int(float(temp)))\n",
    "    curr_onset_time=np.array(curr_onset_time)\n",
    "    return curr_onset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seizure_file = open('/home/maestroj/medical_analysis/project2/seizure_times.csv','r',newline='')\n",
    "reader = csv.reader(seizure_file,delimiter=',')\n",
    "onset_times_temp=[]\n",
    "\n",
    "for row in reader:\n",
    "    onset_times_temp.append(row)\n",
    "    \n",
    "onset_times = []\n",
    "total_patient = len(onset_times_temp)\n",
    "event_number = np.zeros(total_patient,dtype=np.int32)\n",
    "#number of events of (i+1) patient = event_number[i]\n",
    "\n",
    "for i in range(total_patient):\n",
    "    event_number[i] = len(onset_times_temp[i])-1\n",
    "\n",
    "for p in range(total_patient):\n",
    "    temp = []\n",
    "    for d in range(event_number[p]):\n",
    "        temp.append(seizure_time_parser(onset_times_temp,p+1,d+1))\n",
    "    onset_times.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of datasets of patients\n",
      "[ 7  7  6  3 10  1  7 13 16  8  8  5  3  6 31  8  2  4]\n",
      "1st patient's seizure time for each data_set\n",
      "[781]\n",
      "9th patient's seizure time for each data_set\n",
      "[array([200]), array([312]), array([624]), array([762]), array([752]), array([772]), array([884]), array([502]), array([ 94, 258]), array([836]), array([650]), array([636]), array([576]), array([656]), array([638]), array([706])]\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of datasets of patients\")\n",
    "print(event_number)\n",
    "print(\"1st patient's seizure time for each data_set\")\n",
    "print(onset_times[0][1])\n",
    "print(\"9th patient's seizure time for each data_set\")\n",
    "print(onset_times[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def stft_load(patient_number, dataset_number):\n",
    "    input_folder_path = '/home/maestroj/medical_analysis/stft_data/'\n",
    "    input_data_name = '{}_{}.csv'.format(patient_number,dataset_number)\n",
    "    input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "    input_file = open(input_data_path,'r',newline='')\n",
    "    reader = csv.reader(input_file, delimiter=',')\n",
    "    print(\"{} is loaded\".format(input_data_name))\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    try:\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    except: \n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[0])):\n",
    "                temp[i][j]=abs(complex(temp[i][j].replace('i','j')))\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    \n",
    "    temp = np.transpose(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def stft_normal(dataset_number):\n",
    "    input_folder_path = '/home/maestroj/medical_analysis/stft_normal'\n",
    "    input_data_name = '{}.csv'.format(dataset_number)\n",
    "    input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "    input_file = open(input_data_path,'r',newline='')\n",
    "    reader = csv.reader(input_file, delimiter=',')\n",
    "    print(\"{} is loaded\".format(input_data_name))\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    try:\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "    except: \n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[0])):\n",
    "                temp[i][j]=abs(complex(temp[i][j].replace('i','j')))\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "        \n",
    "    temp = np.transpose(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def time_axis_maker(array, sec_per_cell,init = 0):\n",
    "    final = init + sec_per_cell*(len(array)-1)\n",
    "    return np.linspace(init,final,len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_1.csv is loaded\n",
      "(499, 32769)\n"
     ]
    }
   ],
   "source": [
    "temp = stft_load(8,1)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1.csv is loaded\n",
      "(499, 32769)\n",
      "1_2.csv is loaded\n",
      "(499, 32769)\n",
      "1_3.csv is loaded\n",
      "(499, 32769)\n",
      "1_4.csv is loaded\n",
      "(499, 32769)\n",
      "1_5.csv is loaded\n",
      "(499, 32769)\n",
      "1_6.csv is loaded\n",
      "(499, 32769)\n",
      "1_7.csv is loaded\n",
      "(499, 32769)\n",
      "2_1.csv is loaded\n",
      "(499, 32769)\n",
      "2_2.csv is loaded\n",
      "(499, 32769)\n",
      "2_3.csv is loaded\n",
      "(499, 32769)\n",
      "2_4.csv is loaded\n",
      "(499, 32769)\n",
      "2_5.csv is loaded\n",
      "(499, 32769)\n",
      "2_6.csv is loaded\n",
      "(499, 32769)\n",
      "2_7.csv is loaded\n",
      "(499, 32769)\n",
      "3_1.csv is loaded\n",
      "(499, 32769)\n",
      "3_5.csv is loaded\n",
      "(499, 32769)\n",
      "3_6.csv is loaded\n",
      "(499, 32769)\n",
      "4_1.csv is loaded\n",
      "(499, 32769)\n",
      "4_2.csv is loaded\n",
      "(499, 32769)\n",
      "4_3.csv is loaded\n",
      "(499, 32769)\n",
      "5_2.csv is loaded\n",
      "(499, 32769)\n",
      "5_3.csv is loaded\n",
      "(499, 32769)\n",
      "5_4.csv is loaded\n",
      "(499, 32769)\n",
      "6_1.csv is loaded\n",
      "(499, 32769)\n",
      "7_1.csv is loaded\n",
      "(499, 32769)\n",
      "7_2.csv is loaded\n",
      "(499, 32769)\n",
      "7_3.csv is loaded\n",
      "(499, 32769)\n",
      "7_4.csv is loaded\n",
      "(499, 32769)\n",
      "7_5.csv is loaded\n",
      "(499, 32769)\n",
      "7_6.csv is loaded\n",
      "(499, 32769)\n",
      "7_7.csv is loaded\n",
      "(499, 32769)\n",
      "8_1.csv is loaded\n",
      "(499, 32769)\n",
      "8_2.csv is loaded\n",
      "(499, 32769)\n",
      "8_3.csv is loaded\n",
      "(499, 32769)\n",
      "8_4.csv is loaded\n",
      "(499, 32769)\n",
      "8_5.csv is loaded\n",
      "(499, 32769)\n",
      "8_6.csv is loaded\n",
      "(499, 32769)\n",
      "8_7.csv is loaded\n",
      "(499, 32769)\n",
      "8_9.csv is loaded\n",
      "(499, 32769)\n",
      "8_10.csv is loaded\n",
      "(499, 32769)\n",
      "8_11.csv is loaded\n",
      "(499, 32769)\n",
      "8_12.csv is loaded\n",
      "(499, 32769)\n",
      "8_13.csv is loaded\n",
      "(499, 32769)\n",
      "9_3.csv is loaded\n",
      "(499, 32769)\n",
      "9_4.csv is loaded\n",
      "(499, 32769)\n",
      "9_5.csv is loaded\n",
      "(499, 32769)\n",
      "9_6.csv is loaded\n",
      "(499, 32769)\n",
      "9_7.csv is loaded\n",
      "(499, 32769)\n",
      "9_8.csv is loaded\n",
      "(499, 32769)\n",
      "9_10.csv is loaded\n",
      "(499, 32769)\n",
      "9_11.csv is loaded\n",
      "(499, 32769)\n",
      "9_12.csv is loaded\n",
      "(499, 32769)\n",
      "9_13.csv is loaded\n",
      "(499, 32769)\n",
      "9_14.csv is loaded\n",
      "(499, 32769)\n",
      "9_15.csv is loaded\n",
      "(499, 32769)\n",
      "9_16.csv is loaded\n",
      "(499, 32769)\n",
      "11_1.csv is loaded\n",
      "(499, 32769)\n",
      "11_2.csv is loaded\n",
      "(499, 32769)\n",
      "11_3.csv is loaded\n",
      "(499, 32769)\n",
      "11_4.csv is loaded\n",
      "(499, 32769)\n",
      "11_5.csv is loaded\n",
      "(499, 32769)\n",
      "11_6.csv is loaded\n",
      "(499, 32769)\n",
      "11_7.csv is loaded\n",
      "(499, 32769)\n",
      "11_8.csv is loaded\n",
      "(499, 32769)\n",
      "12_1.csv is loaded\n",
      "(499, 32769)\n",
      "13_1.csv is loaded\n",
      "(499, 32769)\n",
      "13_2.csv is loaded\n",
      "(499, 32769)\n",
      "13_3.csv is loaded\n",
      "(499, 32769)\n",
      "14_1.csv is loaded\n",
      "(499, 32769)\n",
      "14_2.csv is loaded\n",
      "(499, 32769)\n",
      "14_3.csv is loaded\n",
      "(499, 32769)\n",
      "14_4.csv is loaded\n",
      "(499, 32769)\n",
      "14_5.csv is loaded\n",
      "(499, 32769)\n",
      "14_6.csv is loaded\n",
      "(499, 32769)\n",
      "15_1.csv is loaded\n",
      "(499, 32769)\n",
      "15_2.csv is loaded\n",
      "(499, 32769)\n",
      "15_3.csv is loaded\n",
      "(499, 32769)\n",
      "15_9.csv is loaded\n",
      "(499, 32769)\n",
      "15_10.csv is loaded\n",
      "(499, 32769)\n",
      "15_13.csv is loaded\n",
      "(499, 32769)\n",
      "15_14.csv is loaded\n",
      "(499, 32769)\n",
      "15_15.csv is loaded\n",
      "(499, 32769)\n",
      "15_16.csv is loaded\n",
      "(499, 32769)\n",
      "15_18.csv is loaded\n",
      "(499, 32769)\n",
      "15_19.csv is loaded\n",
      "(499, 32769)\n",
      "15_21.csv is loaded\n",
      "(499, 32769)\n",
      "15_22.csv is loaded\n",
      "(499, 32769)\n",
      "15_23.csv is loaded\n",
      "(499, 32769)\n",
      "15_24.csv is loaded\n",
      "(499, 32769)\n",
      "15_25.csv is loaded\n",
      "(499, 32769)\n",
      "15_26.csv is loaded\n",
      "(499, 32769)\n",
      "15_27.csv is loaded\n",
      "(499, 32769)\n",
      "15_29.csv is loaded\n",
      "(499, 32769)\n",
      "15_30.csv is loaded\n",
      "(499, 32769)\n",
      "16_1.csv is loaded\n",
      "(499, 32769)\n",
      "16_2.csv is loaded\n",
      "(499, 32769)\n",
      "16_3.csv is loaded\n",
      "(499, 32769)\n",
      "16_4.csv is loaded\n",
      "(499, 32769)\n",
      "16_5.csv is loaded\n",
      "(499, 32769)\n",
      "16_6.csv is loaded\n",
      "(499, 32769)\n",
      "16_7.csv is loaded\n",
      "(499, 32769)\n",
      "16_8.csv is loaded\n",
      "(499, 32769)\n",
      "17_1.csv is loaded\n",
      "(499, 32769)\n",
      "17_2.csv is loaded\n",
      "(499, 32769)\n",
      "18_1.csv is loaded\n",
      "(499, 32769)\n",
      "18_3.csv is loaded\n",
      "(499, 32769)\n",
      "18_4.csv is loaded\n",
      "(499, 32769)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sstft_normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8e4bc1fef523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msstft_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sstft_normal' is not defined"
     ]
    }
   ],
   "source": [
    "input_data = []\n",
    "for i in range(total_patient):\n",
    "    for j in range(event_number[i]):\n",
    "        try:\n",
    "            temp = stft_load(i+1,j+1)\n",
    "            print(temp.shape)\n",
    "            for k in range(len(temp)):\n",
    "                input_data.append(temp[k])\n",
    "            \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            continue;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.csv is loaded\n",
      "(499, 32769)\n",
      "2.csv is loaded\n",
      "(499, 32769)\n",
      "3.csv is loaded\n",
      "(499, 32769)\n",
      "4.csv is loaded\n",
      "(499, 32769)\n",
      "5.csv is loaded\n",
      "(499, 32769)\n",
      "6.csv is loaded\n",
      "(499, 32769)\n",
      "7.csv is loaded\n",
      "(499, 32769)\n",
      "8.csv is loaded\n",
      "(499, 32769)\n",
      "9.csv is loaded\n",
      "(499, 32769)\n",
      "10.csv is loaded\n",
      "(499, 32769)\n",
      "11.csv is loaded\n",
      "(499, 32769)\n",
      "12.csv is loaded\n",
      "(499, 32769)\n",
      "13.csv is loaded\n",
      "(499, 32769)\n",
      "14.csv is loaded\n",
      "(499, 32769)\n",
      "15.csv is loaded\n",
      "(499, 32769)\n",
      "16.csv is loaded\n",
      "(499, 32769)\n",
      "17.csv is loaded\n",
      "(499, 32769)\n",
      "(61876, 32769)\n"
     ]
    }
   ],
   "source": [
    "for i in range(normal):\n",
    "    try:\n",
    "        temp = stft_normal(i)\n",
    "        print(temp.shape)\n",
    "        for k in range(len(temp)):\n",
    "            input_data.append(temp[k])\n",
    "    except FileNotFoundError:\n",
    "        continue;\n",
    "\n",
    "input_data = np.array(input_data)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,input_size])\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([input_size,hidden_layer], -0.01, 0.01))\n",
    "b1 = tf.Variable(tf.random_uniform([1, hidden_layer], -0.01, 0.01))\n",
    "\n",
    "w2 = tf.Variable(tf.random_uniform([hidden_layer,input_size], -0.01, 0.01))\n",
    "b2 = tf.Variable(tf.random_uniform([1, input_size], -0.01, 0.01))\n",
    "\n",
    "H = tf.matmul(X, w1) + b1\n",
    "hypothesis = tf.matmul(H, w2) + b2\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(X-hypothesis))\n",
    "optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th run cost : 124641.3203125 \n",
      "100th run cost : 15637.736328125 \n",
      "200th run cost : 12545.3115234375 \n",
      "300th run cost : 9894.990234375 \n",
      "400th run cost : 9864.630859375 \n",
      "500th run cost : 9861.4580078125 \n",
      "600th run cost : 9860.7890625 \n",
      "700th run cost : 9860.634765625 \n",
      "800th run cost : 9865.08203125 \n",
      "900th run cost : 9860.5166015625 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-051df8a41c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             print(\"{}th run cost : {} \".format(step,\n",
      "\u001b[0;32m/home/maestroj/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maestroj/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maestroj/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/maestroj/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maestroj/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_number= 100\n",
    "batch_size = int(len(input_data)/batch_number)\n",
    "for i in range(batch_number):\n",
    "    for step in range(train_steps+1):\n",
    "        sess.run(train, feed_dict={X: input_data[i*batch_size:(i+1)*batch_size]})\n",
    "        if step%100==0:\n",
    "            print(\"{}th run cost : {} \".format(step,\n",
    "                                        sess.run(cost,feed_dict={X: input_data[i*batch_size:(i+1)*batch_size]})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1.csv is loaded\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a34d5f489d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstft_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mtemp_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mtemp_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(total_patient):\n",
    "    for j in range(event_number[i]):\n",
    "        try:\n",
    "            temp = stft_load(i+1,j+1)\n",
    "            temp_output = sess.run(H, feed_dict = {X : temp})\n",
    "            temp_output = np.transpose(temp_output)\n",
    "            \n",
    "            output_file_path = '/home/maestroj/medical_analysis/stft_data_reduced'\n",
    "            output_file_name = '{}_{}.csv'.format(i+1, j+1)\n",
    "            output_file_name = os.path.join(output_file_path,out_file_name)\n",
    "            \n",
    "            print(\"Reduced data is stored in {}\".format(output_file_name))\n",
    "            \n",
    "            csv_file = open(output_file_name1, \"w\")\n",
    "            cw = csv.writer(csv_file , delimiter=',')\n",
    "            size = train_length\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            continue;\n",
    "            \n",
    "for i in range(normal):\n",
    "    try:\n",
    "        temp = stft_normal(i)\n",
    "        print(temp.shape)\n",
    "        for k in range(len(temp)):\n",
    "            input_data.append(temp[k])\n",
    "    except FileNotFoundError:\n",
    "        continue;\n",
    "\n",
    "input_data = np.array(input_data)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
