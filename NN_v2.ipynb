{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Channel data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "channels=['Fp1','F3','C3','P3','F7', 'T7',  'P7', 'O1', 'F9', 'FT9', 'T9', 'P9', 'FP2','F4', 'C4','P4','F8','T8','P8','O2', 'F10','Ft10','T10','P10','FZ','CZ','OZ','Sp1', 'Sp2', 'EKG']         \n",
    "channel_dict={}\n",
    "for i in range(len(channels)):\n",
    "    channel_dict[channels[i]]=i\n",
    "Selected_electrod=['Sp1', 'Sp2', 'T8', 'P8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dataload(patient_number, dataset_number):\n",
    "    try :\n",
    "        input_folder_path = '/home/maestroj/medical_analysis/eeg_csv'\n",
    "        input_data_name = 'data{}_{}.csv'.format(patient_number,dataset_number)\n",
    "        input_data_path = os.path.join(input_folder_path,input_data_name)\n",
    "        input_file = open(input_data_path,'r',newline='')\n",
    "        reader = csv.reader(input_file, delimiter=',')\n",
    "        print(\"{} is loaded\".format(input_data_name))\n",
    "        temp = []\n",
    "        for row in reader:\n",
    "            temp.append(row)\n",
    "        temp = np.array(temp, dtype=np.float32)\n",
    "        temp = np.transpose(temp)\n",
    "        return temp\n",
    "    except FileNotFoundError:\n",
    "        print(\"No such File\")\n",
    "        temp = []\n",
    "        temp = np.array(temp)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Onset-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seizure_time_parser(onset_times,patient_number,data_set_number):\n",
    "    temp = str(onset_times[patient_number-1][data_set_number])\n",
    "    curr_onset_time = []\n",
    "    while temp.find('/')!=-1:\n",
    "        curr_onset_time.append(int(temp[0:temp.find('/')]))\n",
    "        temp=temp[temp.find('/')+1:]\n",
    "    curr_onset_time.append(int(float(temp)))\n",
    "    curr_onset_time=np.array(curr_onset_time)\n",
    "    return curr_onset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seizure_file = open('seizure_times.csv','r',newline='')\n",
    "reader = csv.reader(seizure_file,delimiter=',')\n",
    "onset_times_temp=[]\n",
    "\n",
    "for row in reader:\n",
    "    onset_times_temp.append(row)\n",
    "    \n",
    "onset_times = []\n",
    "total_patient = len(onset_times_temp)\n",
    "event_number = np.zeros(total_patient,dtype=np.int32)\n",
    "#number of events of (i+1) patient = event_number[i]\n",
    "\n",
    "for i in range(total_patient):\n",
    "    event_number[i] = len(onset_times_temp[i])-1\n",
    "\n",
    "for p in range(total_patient):\n",
    "    temp = []\n",
    "    for d in range(event_number[p]):\n",
    "        temp.append(seizure_time_parser(onset_times_temp,p+1,d+1))\n",
    "    onset_times.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of datasets of patients\n",
      "[ 7  7  6  3 10  1  7 13 16  8  8  5  3  6 31  8  2  4]\n",
      "1st patient's seizure time for each data_set\n",
      "[array([820]), array([781]), array([626]), array([713]), array([807]), array([792]), array([780])]\n",
      "9th patient's seizure time for each data_set\n",
      "[array([200]), array([312]), array([624]), array([762]), array([752]), array([772]), array([884]), array([502]), array([ 94, 258]), array([836]), array([650]), array([636]), array([576]), array([656]), array([638]), array([706])]\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of datasets of patients\")\n",
    "print(event_number)\n",
    "print(\"1st patient's seizure time for each data_set\")\n",
    "print(onset_times[0])\n",
    "print(\"9th patient's seizure time for each data_set\")\n",
    "print(onset_times[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Setting hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_size = 100\n",
    "\n",
    "input_data_size = data_size*3\n",
    "\n",
    "error_range = 5\n",
    "sampling_rate = 200\n",
    "striding = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def downgrade_and_sum_up(temp):\n",
    "    \"\"\"\n",
    "    downgrade with striding information \n",
    "    return 3 arrays max, min ,average\n",
    "    \"\"\"\n",
    "    nchannels = temp.shape[0]\n",
    "    data_length = temp.shape[1]\n",
    "    reduced_data_length = int(data_length/striding)\n",
    "    max_array = np.zeros(reduced_data_length)\n",
    "    min_array = np.zeros(reduced_data_length)\n",
    "    average_array = np.zeros(reduced_data_length)\n",
    "    for i in range(reduced_data_length):\n",
    "        for channel in range(nchannels):\n",
    "            max_array[i] += np.max(temp[channel][striding*i:striding*(i+1)])\n",
    "            min_array[i] += np.min(temp[channel][striding*i:striding*(i+1)])\n",
    "            average_array[i] += np.average(temp[channel][striding*i:striding*(i+1)])\n",
    "    return {'max' : max_array,'min' : min_array,'average':average_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize_max(array):\n",
    "    temp = np.zeros(len(array),dtype=np.float32)\n",
    "    min = np.min(array)\n",
    "    max = np.max(array)\n",
    "    for i in range(len(array)):\n",
    "        temp[i]=(array[i]-min)/(max-min)\n",
    "    return temp\n",
    "\n",
    "def normalize_min(array):\n",
    "    temp = np.zeros(len(array),dtype=np.float32)\n",
    "    min = np.min(array)\n",
    "    max = np.max(array)\n",
    "    for i in range(len(array)):\n",
    "        temp[i]=(max-array[i])/(max-min)\n",
    "    return temp\n",
    "\n",
    "def normalize_average(array):\n",
    "    temp = np.zeros(len(array),dtype=np.float32)\n",
    "    average = np.average(array)\n",
    "    min = np.min(array)\n",
    "    max = np.max(array)\n",
    "    for i in range(len(array)):\n",
    "        temp[i]=(array[i]-average)/(max-min)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_set_generator(patient_number, dataset_number):\n",
    "    temp = dataload(patient_number, dataset_number)\n",
    "    onset_times_temp = onset_times[patient_number-1][dataset_number-1]        \n",
    "    \n",
    "    result = downgrade_and_sum_up(temp)\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    \n",
    "    nchannels = temp.shape[0]\n",
    "    \n",
    "    reduced_data_length = len(result['max'])\n",
    "    \n",
    "    result['max'] = normalize_max(result['max'])\n",
    "    result['min'] = normalize_min(result['min'])\n",
    "    result['average'] = normalize_average(result['average'])\n",
    "        \n",
    "    for i in range(reduced_data_length):\n",
    "        initial_point = i\n",
    "        final_point = i+data_size \n",
    "        mid_point = (initial_point + final_point)/2\n",
    "        if final_point > reduced_data_length:\n",
    "            break\n",
    "\n",
    "        input_temp = []\n",
    "            \n",
    "        for k in range(initial_point,final_point):\n",
    "            input_temp.append(result['max'][k])\n",
    "            input_temp.append(result['min'][k])\n",
    "            input_temp.append(result['average'][k])\n",
    "\n",
    "        output_temp = 0\n",
    "        for k in range(len(onset_times_temp)):\n",
    "            position = onset_times_temp[k]*sampling_rate/striding    \n",
    "            if mid_point < position and position < final_point:\n",
    "                output_temp = 1\n",
    "                break;\n",
    "                \n",
    "        input_data.append(input_temp)\n",
    "        output_data.append(output_temp)\n",
    "       \n",
    "    input_data = np.array(input_data, dtype =np.float32)\n",
    "    output_data = np.array(output_data, dtype = np.float32)\n",
    "    return {'input' : input_data, 'output' : output_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "result = train_set_generator(1, 1)\n",
    "input_data = result['input']\n",
    "output_data =result['output']\n",
    "output_data = np.reshape(output_data, [-1,1])\n",
    "\n",
    "print(input_data.shape)\n",
    "print(output_data.shape)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_data_size])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([input_data_size, 50], stddev=0.01))\n",
    "b_fc1 = tf.Variable(tf.constant(0.01, shape=[50]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(x, W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([50, 50], stddev=0.01))\n",
    "b_fc2 = tf.Variable(tf.constant(0.01, shape=[50]))\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([50, 50], stddev=0.01))\n",
    "b_fc3 = tf.Variable(tf.constant(0.01, shape=[50]))\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "\n",
    "W_fc4 = tf.Variable(tf.truncated_normal([50, 50], stddev=0.01))\n",
    "b_fc4 = tf.Variable(tf.constant(0.01, shape=[50]))\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3, W_fc4) + b_fc4)\n",
    "\n",
    "W_fc5 = tf.Variable(tf.truncated_normal([50, 1], stddev=0.01))\n",
    "b_fc5 = tf.Variable(tf.constant(0.01, shape=[1]))\n",
    "y_hat = tf.sigmoid(tf.matmul(h_fc4, W_fc5) + b_fc5)\n",
    "\n",
    "y_predict = tf.floor(y_hat+0.5)\n",
    "\n",
    "error = tf.reduce_mean((y-y_hat)*(y-y_hat))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(error)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1_1.csv is loaded\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "for k in range(iteration):\n",
    "    for i in range(total_patient):\n",
    "        for j in range(event_number[i]):\n",
    "            result = train_set_generator(i+1, j+1)\n",
    "            input_data = result['input']\n",
    "            output_data =result['output']\n",
    "            output_data = np.reshape(output_data, [-1,1])\n",
    "            plt.plot(output_data)\n",
    "            plt.title('Output_data(patient{}, event{})'.format(i+1, j+1))\n",
    "            plt.show()\n",
    "            for k in range(100):\n",
    "                train_step.run(feed_dict={x : input_data, y : output_data})\n",
    "            print(\"Error = {}\".format(sess.run(error, feed_dict={x: input_data, y: output_data})))\n",
    "            plt.plot(sess.run(y_hat, feed_dict = {x : input_data}))\n",
    "            plt.title('Prediction_data(patient{},event{})'.format(i+1, j+1))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test_set_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_set_generator(temp,onset_times_temp, channel_number):\n",
    "    result = downgrade(temp)\n",
    "    reduced_data_length = result['max'].shape[1]\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    result['max'][channel_number] = normalize_max(result['max'][channel_number])\n",
    "    result['min'][channel_number] = normalize_min(result['min'][channel_number])\n",
    "    result['average'][channel_number] = normalize_average(result['average'][channel_number])\n",
    "    \n",
    "    for i in range(reduced_data_length):\n",
    "        initial_point = i\n",
    "        final_point = i+data_size\n",
    "        mid_point = (initial_point+final_point)/2\n",
    "        \n",
    "        if final_point > reduced_data_length:\n",
    "            break\n",
    "        input_temp = []\n",
    "        for k in range(initial_point,final_point):\n",
    "            input_temp.append(result['max'][channel_number][k])\n",
    "            input_temp.append(result['min'][channel_number][k])\n",
    "            input_temp.append(result['average'][channel_number][k])\n",
    "        output_temp = 0\n",
    "\n",
    "        onset_times_temp = onset_times[patient_number-1][dataset_number-1]\n",
    "        for k in range(len(onset_times_temp)):\n",
    "            position = onset_times_temp[k]*sampling_rate/striding\n",
    "            if mid_point < position and position < final_point:\n",
    "                output_temp = 1\n",
    "                break;\n",
    "        input_data.append(input_temp)\n",
    "        output_data.append(output_temp) \n",
    "\n",
    "    input_data = np.array(input_data, dtype =np.float32)\n",
    "    output_data = np.array(output_data, dtype = np.float32)\n",
    "    return {'input' :  input_data, 'output' : output_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "patient_number = 9\n",
    "dataset_number = 5\n",
    "\n",
    "temp = dataload(patient_number, dataset_number)\n",
    "nchannels = temp.shape[0]\n",
    "onset_times_temp = onset_times[patient_number-1][dataset_number-1]\n",
    "\n",
    "flag = 0\n",
    "\n",
    "for channel_number in range(nchannels):\n",
    "    result = test_set_generator(temp,onset_times_temp,channel_number)\n",
    "    val_input = result['input']\n",
    "    val_output = result['output']\n",
    "\n",
    "    if flag==0:\n",
    "        flag=1\n",
    "        time_step_size = striding/sampling_rate\n",
    "        time = np.zeros(val_input.shape[0])\n",
    "        for i in range(len(time)):\n",
    "            time[i] = (i + data_size)*time_step_size   \n",
    "        plt.plot(time, val_output)\n",
    "        plt.title(\"Seizure_time_output(patient {}, event {})\"\n",
    "                    .format(patient_number,dataset_number))\n",
    "        plt.set_xlabel('sec')\n",
    "        plt.vlines(onset_times[patient_number-1][dataset_number-1],0,1.5, color='r'\n",
    "                   , alpha=0.9, linestyle='--', label='Onsets')\n",
    "        plt.show()\n",
    "\n",
    "    prediction = sess.run(y_predict, feed_dict={x: val_input})\n",
    "    plt.plot(time, prediction)\n",
    "    plt.title(\"Prediction(patient {}, event {}, Channel {})\"\n",
    "                .format(patient_number,dataset_number,channel_number))\n",
    "    plt.set_xlabel('sec')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
