{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.ops import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sec_per_ar = 0.5\n",
    "ar_per_sec = 1/sec_per_ar\n",
    "time_length = 1000\n",
    "train_steps = 10000\n",
    "check_steps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load patient ar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "folder_path = '/home/maestoj/medical_analysis/ar100/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ar_data_load(patient_number,data_set_number):\n",
    "    file_name = \"data_patient_{}_AR{}.csv\".format(patient_number,data_set_number)\n",
    "    file_path = folder_path+file_name\n",
    "    ar_file = open(file_path,'r',newline='')\n",
    "    reader = csv.reader(ar_file, delimiter= ',')\n",
    "    temp = []\n",
    "    for row in reader:\n",
    "        temp.append(row)\n",
    "    temp = np.array(temp, dtype = np.float32)\n",
    "    print(\"{} is loaded from {}\".format(file_name, file_path))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ar_data_average_channels(ar_datas):\n",
    "    a, b = ar_datas.shape\n",
    "    temp = np.zeros(b)\n",
    "    for i in range(b):\n",
    "        for j in range(a):\n",
    "            temp[i] += ar_datas[j][i]\n",
    "        temp[i] /=a\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ar_data_select_channel(ar_datas, channel_number):\n",
    "    return ar_datas[channel_number - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalizer(array):\n",
    "    temp_max = np.max(array)\n",
    "    temp_min = np.min(array)\n",
    "    temp = np.zeros(len(array))\n",
    "    for i in range(len(array)):\n",
    "        temp[i] = (array[i]-temp_min)/(temp_max-temp_min)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def time_axis_maker(array, sec_per_cell,init = 0):\n",
    "    final = init + sec_per_cell*(len(array)-1)\n",
    "    return np.linspace(init,final,len(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test functions and librosa test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = ar_data_average_channels(ar_data_load(1,1))\n",
    "time = time_axis_maker(y,sec_per_ar)\n",
    "plt.plot(time, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# percurssion graph\n",
    "for patient_number in range(1, len(onset_times)+1):\n",
    "    for dataset_number in range(1, event_number[patient_number-1]+1):\n",
    "        y = ar_data_sum_channels(ar_data_load(patient_number,dataset_number))\n",
    "        temp = time_axis_maker(y,sec_per_ar)\n",
    "        temp_max = np.max(y)\n",
    "        plt.plot(temp, y)\n",
    "        plt.title('{}, {}'.format(patient_number, dataset_number))\n",
    "        plt.vlines(onset_times[patient_number-1][dataset_number-1],0,temp_max, color='r', alpha=0.9,\n",
    "                        linestyle='--', label='Onsets')\n",
    "        plt.show()\n",
    "        y_harm, y_perc = librosa.effects.hpss(y)\n",
    "        librosa.display.waveplot(y_perc, alpha=0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# librosa stft\n",
    "D_short = librosa.stft(y,win_length = 100, hop_length = 100)\n",
    "print(D_short.shape)\n",
    "librosa.display.specshow(abs(D_short))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_file = open('model_v1_label.csv','r',newline='')\n",
    "reader = csv.reader(label_file,delimiter=',')\n",
    "label = []\n",
    "for row in reader:\n",
    "    label.append(row)\n",
    "label = np.array(label)\n",
    "label = label.astype(np.float)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Onset-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seizure_time_parser(onset_times,patient_number,data_set_number):\n",
    "    temp = str(onset_times[patient_number-1][data_set_number])\n",
    "    curr_onset_time = []\n",
    "    while temp.find('/')!=-1:\n",
    "        curr_onset_time.append(int(temp[0:temp.find('/')]))\n",
    "        temp=temp[temp.find('/')+1:]\n",
    "    curr_onset_time.append(int(float(temp)))\n",
    "    curr_onset_time=np.array(curr_onset_time)\n",
    "    return curr_onset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seizure_file = open('seizure_times.csv','r',newline='')\n",
    "reader = csv.reader(seizure_file,delimiter=',')\n",
    "onset_times_temp=[]\n",
    "\n",
    "for row in reader:\n",
    "    onset_times_temp.append(row)\n",
    "    \n",
    "onset_times = []\n",
    "total_patient = len(onset_times_temp)\n",
    "event_number = np.zeros(total_patient,dtype=np.int32)\n",
    "#number of events of (i+1) patient = event_number[i]\n",
    "\n",
    "for i in range(total_patient):\n",
    "    event_number[i] = len(onset_times_temp[i])-1\n",
    "\n",
    "for p in range(total_patient):\n",
    "    temp = []\n",
    "    for d in range(event_number[p]):\n",
    "        temp.append(seizure_time_parser(onset_times_temp,p+1,d+1))\n",
    "    onset_times.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"The number of datasets of patients\")\n",
    "print(event_number)\n",
    "print(\"2st patient's seizure time for each data_set\")\n",
    "print(onset_times[1])\n",
    "print(\"9th patient's seizure time for each data_set\")\n",
    "print(onset_times[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training_set and test_set generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(label))\n",
    "i=51\n",
    "patient_number = int(label[i][0])\n",
    "dataset_number = int(label[i][1])\n",
    "temp_output = label[i][2]\n",
    "print(patient_number, dataset_number)\n",
    "temp = normalizer(ar_data_average_channels(ar_data_load(patient_number, dataset_number)))\n",
    "time = time_axis_maker(temp,sec_per_ar)\n",
    "plt.plot(time, temp)\n",
    "plt.show()\n",
    "\n",
    "print(len(temp))\n",
    "onset_time_temp = onset_times[patient_number-1][dataset_number-1]            \n",
    "print(onset_time_temp)\n",
    "temp_input_data = np.zeros(time_length)\n",
    "\n",
    "onset_on_ar = int(onset_time_temp*ar_per_sec)\n",
    "print(onset_on_ar)\n",
    "for i in range(time_length):\n",
    "    temp_input_data[i] = temp[onset_on_ar-time_length+1+i]\n",
    "time2 = time_axis_maker(temp_input_data,sec_per_ar,(onset_on_ar-time_length)*sec_per_ar)\n",
    "\n",
    "y_max = np.max(temp_input_data)\n",
    "plt.plot(time2,temp_input_data)\n",
    "plt.vlines(onset_time_temp-temp_output, 0, y_max, colors='r', linestyles='--')\n",
    "plt.show()\n",
    "\n",
    "print(temp_output)\n",
    "\n",
    "train_input = []\n",
    "train_output = []\n",
    "test_input = []\n",
    "test_output = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_set_generator():\n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []\n",
    "    test_input = []\n",
    "    test_output = []\n",
    "    total_data_number = len(label)\n",
    "    train_data_number = total_data_number*0.8\n",
    "    for label_seq in range(total_data_number):\n",
    "        patient_number = int(label[label_seq][0])\n",
    "        dataset_number = int(label[label_seq][1])\n",
    "\n",
    "        temp = normalizer(ar_data_average_channels(ar_data_load(patient_number, dataset_number)))\n",
    "        onset_time_temp = onset_times[patient_number-1][dataset_number-1]            \n",
    "        \n",
    "        if len(onset_time_temp) > 1:\n",
    "            print(\"More than one onset time\")\n",
    "            continue\n",
    "    \n",
    "        onset_time_temp = onset_time_temp[0]\n",
    "    \n",
    "        if onset_time_temp*ar_per_sec < time_length:\n",
    "            print(\"Wrong input\")\n",
    "            continue\n",
    "        \n",
    "        temp_input_data = np.zeros(time_length)\n",
    "        temp_output_data = label[label_seq][2]\n",
    "        \n",
    "        onset_on_ar = int(onset_time_temp*ar_per_sec)\n",
    "        \n",
    "        if onset_on_ar > len(temp):\n",
    "            print(\"Out of boundary\")\n",
    "            continue\n",
    "        \n",
    "        for i in range(time_length):\n",
    "            temp_input_data[i] = temp[onset_on_ar-time_length+1+i]\n",
    "\n",
    "        if label_seq < train_data_number:\n",
    "            train_input.append(temp_input_data)\n",
    "            train_output.append(temp_output_data)\n",
    "        else:\n",
    "            test_input.append(temp_input_data)\n",
    "            test_output.append(temp_output_data)\n",
    "            \n",
    "    train_input = np.array(train_input)\n",
    "    train_output = np.array(train_output)\n",
    "    test_input = np.array(test_input)\n",
    "    test_output = np.array(test_output)\n",
    "    return {'train_input' : train_input, 'train_output' : train_output, \n",
    "            'test_input' : test_input,'test_output' : test_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = train_and_test_set_generator()\n",
    "train_input = result['train_input']\n",
    "train_output = result['train_output']\n",
    "test_input = result['test_input']\n",
    "test_output = result['test_output']\n",
    "train_output = np.reshape(train_output,[-1,1])\n",
    "test_output = np.reshape(test_output,[-1,1])\n",
    "print(train_input.shape)\n",
    "print(train_output.shape)\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, time_length])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "weights = {\"w_conv1\" : tf.Variable(tf.truncated_normal([5, 1, 1, 16], stddev=0.1)),\n",
    "           \"w_conv2\" : tf.Variable(tf.truncated_normal([5, 1, 16, 32], stddev=0.1)),\n",
    "           \"w_fc1\" : tf.Variable(tf.truncated_normal([40*32, 100], stddev=0.1)),\n",
    "           \"w_out\" : tf.Variable(tf.truncated_normal([100, 1], stddev=0.1))\n",
    "          }\n",
    "\n",
    "biases = {\"b_conv1\" : tf.Variable(tf.constant(0.1, shape=[16])),\n",
    "          \"b_conv2\" : tf.Variable(tf.constant(0.1, shape=[32])),\n",
    "            \"b_fc1\" : tf.Variable(tf.constant(0.1, shape=[100])),\n",
    "           \"b_out\" : tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "        }\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool1d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,5,1,1], strides=[1,5,1,1], padding='SAME')\n",
    "\n",
    "train_x = tf.reshape(x, [-1,time_length,1,1])\n",
    "conv1 = conv1d(train_x,weights[\"w_conv1\"])\n",
    "relu1 = tf.nn.relu(conv1 + biases[\"b_conv1\"])\n",
    "pool1 = maxpool1d(relu1)\n",
    "print(relu1)\n",
    "print(pool1)\n",
    "\n",
    "conv2 = conv1d(pool1,weights[\"w_conv2\"])\n",
    "relu2 = tf.nn.relu(conv2 + biases[\"b_conv2\"])\n",
    "pool2 = maxpool1d(relu2)\n",
    "print(relu2)\n",
    "print(pool2)\n",
    "\n",
    "pool2_temp = tf.reshape(pool2, [-1,40*32])\n",
    "h1 = tf.nn.relu(tf.matmul(pool2_temp, weights[\"w_fc1\"])+ biases[\"b_fc1\"])\n",
    "y_hat = tf.matmul(h1, weights[\"w_out\"])+ biases[\"b_out\"]\n",
    "print(y_hat)\n",
    "#h_conv = tf.nn.conv2d(x_image, W_conv, strides=[1, 1, 1, 1], padding='VALID')\n",
    "#h_relu = tf.nn.relu(h_conv + b_conv)\n",
    "#h_pool = tf.nn.max_pool(h_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_hat-y))\n",
    "train = tf.train.AdamOptimizer(1e-3).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_output)\n",
    "plt.show()\n",
    "for i in range(train_steps):\n",
    "    opt, c = sess.run([train, cost], feed_dict={x: train_input, y: train_output})\n",
    "    if i%int(check_steps)==0:\n",
    "        print(\"Cost = {}\".format(c))\n",
    "        plt.plot(sess.run(y_hat, feed_dict = {x : train_input}))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(cost, feed_dict={x: test_input,y:test_output}))\n",
    "plt.plot(test_output)\n",
    "plt.show()\n",
    "plt.plot(sess.run(y_hat, feed_dict = {x : test_input}))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
